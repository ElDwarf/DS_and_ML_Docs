{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright-notice"
   },
   "source": [
    "#### Copyright 2017 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "copyright-notice2"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Primeros pasos con TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bd2Zkk1LE2Zr"
   },
   "source": [
    " **Objetivos de aprendizaje:**\n",
    "  * aprender los conceptos fundamentales de TensorFlow\n",
    "  * usar la clase `LinearRegressor` en TensorFlow para predecir el precio mediano de la vivienda, en el nivel de detalle de las manzanas, basado en un atributo de entrada\n",
    "  * evaluar la exactitud de las predicciones de un modelo a través del error de la raíz cuadrada de la media (RMSE)\n",
    "  * mejorar la exactitud de un modelo al ajustar sus hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxiIKhP4E2Zr"
   },
   "source": [
    " Los datos se basan en el censo que se realizó en 1990 en California."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    " ## Preparación\n",
    "En esta primera celda, cargaremos las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVFf5asKE2Zt"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    " A continuación, cargaremos nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ivCDWnwE2Zx"
   },
   "outputs": [],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVk_qlG6U80j"
   },
   "source": [
    " Dispondremos los datos de forma aleatoria para asegurarnos de no obtener efectos de orden compulsivo que podrían afectar el rendimiento del descenso de gradiente estocástico. Además, ajustaremos `median_house_value` para que esté en unidades de miles, de manera que se pueda aprender más fácilmente con tasas de aprendizaje en un rango que usamos generalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0eVyguIU80m"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-116.5</td>\n",
       "      <td>33.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5228.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>134.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>332.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>-117.9</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>213.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>-118.4</td>\n",
       "      <td>33.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>427.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>-122.2</td>\n",
       "      <td>37.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>361.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15020</th>\n",
       "      <td>-122.2</td>\n",
       "      <td>38.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>123.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13924</th>\n",
       "      <td>-122.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>284.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12715</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>36.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>184.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>-119.7</td>\n",
       "      <td>36.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>-121.9</td>\n",
       "      <td>37.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2428.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>254.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "222       -116.5      33.8                16.0       5228.0           992.0   \n",
       "4360      -118.0      34.0                23.0       1995.0           306.0   \n",
       "3371      -117.9      33.8                34.0       1410.0           214.0   \n",
       "7758      -118.4      33.8                35.0       2152.0           454.0   \n",
       "15006     -122.2      37.5                40.0       4459.0          1027.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "15020     -122.2      38.1                24.0       2917.0           543.0   \n",
       "13924     -122.0      37.4                41.0       2123.0           425.0   \n",
       "12715     -121.8      36.9                24.0       1943.0           447.0   \n",
       "9748      -119.7      36.6                 6.0       1931.0           422.0   \n",
       "13149     -121.9      37.5                15.0       2428.0           513.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "222        1177.0       639.0            3.1               134.6  \n",
       "4360        707.0       293.0            8.7               332.7  \n",
       "3371        837.0       240.0            6.1               213.9  \n",
       "7758        902.0       414.0            4.5               427.2  \n",
       "15006      2080.0       982.0            3.5               361.9  \n",
       "...           ...         ...            ...                 ...  \n",
       "15020      1878.0       531.0            3.7               123.6  \n",
       "13924      1032.0       435.0            4.7               284.8  \n",
       "12715      1844.0       461.0            3.0               184.3  \n",
       "9748       1344.0       414.0            1.7                58.0  \n",
       "13149      1687.0       519.0            4.8               254.4  \n",
       "\n",
       "[17000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "california_housing_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " ## Análisis de los datos\n",
    "\n",
    "Una buena idea es conocer un poco los datos antes de trabajar con ellos.\n",
    "\n",
    "Imprimiremos un breve resumen de algunas estadísticas útiles de cada columna: conteo de ejemplos, media, desviación estándar, máx., mín. y varios cuantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9               207.3  \n",
       "std        1147.9       384.5            1.9               116.0  \n",
       "min           3.0         1.0            0.5                15.0  \n",
       "25%         790.0       282.0            2.6               119.4  \n",
       "50%        1167.0       409.0            3.5               180.4  \n",
       "75%        1721.0       605.2            4.8               265.0  \n",
       "max       35682.0      6082.0           15.0               500.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " ## Creación del primer modelo\n",
    "\n",
    "En este ejercicio, intentaremos predecir `median_house_value`, que será nuestra etiqueta (a veces también denominada objetivo). Usaremos `total_rooms` como nuestro atributo de entrada.\n",
    "\n",
    "**NOTA:** Nuestros datos están a nivel de manzana, de manera que este atributo representa el número total de habitaciones en esa manzana.\n",
    "\n",
    "Para entrenar nuestro modelo, usaremos la interfaz de [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) que proporciona la API de [Estimator](https://www.tensorflow.org/get_started/estimator) de TensorFlow. Esta API se ocupa en gran medida del ajuste del modelo de bajo nivel y presenta métodos convenientes para realizar el entrenamiento, la evaluación y la inferencia del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cpcsieFhsNI"
   },
   "source": [
    " ### Paso 1: Define atributos y configura columnas de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EL8-9d4ZJNR7"
   },
   "source": [
    " Para importar nuestros datos de entrenamiento en TensorFlow, debemos especificar qué tipo de datos contiene cada atributo. Hay dos tipos de datos principales que usaremos en este ejercicio y en otros futuros:\n",
    "\n",
    "* **Datos categóricos**: Datos que son textuales. En este ejercicio, nuestro conjunto de datos de viviendas no contiene atributos categóricos, pero los ejemplos que podrías ver son el estilo de la casa o las palabras en un anuncio de bienes raíces.\n",
    "\n",
    "* **Datos numéricos**: Datos que son un número (entero o de punto flotante) y que quieres tratar como un número. Como se analizará más adelante, a veces quieres tratar los datos numéricos (p. ej., un código postal) como si fueran categóricos.\n",
    "\n",
    "En TensorFlow, indicamos el tipo de datos de un atributo a través de un constructo denominado **columna de atributos**. Las columnas de atributos almacenan solo una descripción de los datos de los atributos; no contienen los datos de los atributos en sí.\n",
    "\n",
    "Para comenzar, usaremos solo un atributo de entrada numérica, `total_rooms`. El siguiente código extrae los datos de `total_rooms` de nuestro `california_housing_dataframe` y define la columna de atributos con `numeric_column`, que especifica que los datos son numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhEbFCZ86cDZ"
   },
   "outputs": [],
   "source": [
    "# Define the input feature: total_rooms.\n",
    "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
    "\n",
    "# Configure a numeric feature column for total_rooms.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_3S8teX7Rd2"
   },
   "source": [
    " **NOTA:** La forma de nuestros datos de `total_rooms` es una matriz de una dimensión (una lista del número total de habitaciones por cada manzana). Esta es la forma predeterminada para `numeric_column`, de manera que no tenemos que pasarla como un argumento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMl3qrU5MGV6"
   },
   "source": [
    " ### Paso 2: Define el objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cw4nrfcB7kyk"
   },
   "source": [
    " A continuación, definiremos nuestro objetivo, que es `median_house_value`. Nuevamente, podemos extraerlo de nuestro `california_housing_dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1NvvNkH8Kbt"
   },
   "outputs": [],
   "source": [
    "# Define the label.\n",
    "targets = california_housing_dataframe[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M-rTFHL2UkA"
   },
   "source": [
    " ### Paso 3: Configura el regresor lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUfGQUNp7jdL"
   },
   "source": [
    " A continuación, configuraremos un modelo de regresión lineal a través de LinearRegressor. Entrenaremos este modelo mediante el `GradientDescentOptimizer`, que implementa el descenso de gradiente estocástico (SGD) de minilote. El argumento `learning_rate` controla el tamaño del paso de gradiente.\n",
    "\n",
    "**NOTA:** Para estar seguros, también aplicamos [recorte de gradientes](https://developers.google.com/machine-learning/glossary/#gradient_clipping) a nuestro optimizador a través de `clip_gradients_by_norm`. El recorte de gradientes garantiza que la magnitud de los gradientes no se vuelva demasiado grande durante el entrenamiento, lo cual puede provocar que falle el descenso de gradientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubhtW-NGU802"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-15b967a80868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use gradient descent as the optimizer for training the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_gradients_by_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Configure the linear regression model with our feature columns and optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "# Use gradient descent as the optimizer for training the model.\n",
    "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "# Configure the linear regression model with our feature columns and optimizer.\n",
    "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0IztwdK2f3F"
   },
   "source": [
    " ### Paso 4: Define la función de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5M5j6xSCHxx"
   },
   "source": [
    " Para importar nuestros datos de viviendas en California a nuestro `LinearRegressor`, tenemos que definir una función de entrada, que instruye a TensorFlow cómo realizar el procesamiento previo de los datos, además de cómo organizarlos por lotes, aleatorizarlos y repetirlos durante el entrenamiento del modelo.\n",
    "\n",
    "Primero, convertiremos nuestros datos de atributos de *pandas* a un diccionario de matrices de Numpy. A continuación, podemos usar la [API del conjunto de datos](https://www.tensorflow.org/programmers_guide/datasets) de TensorFlow para construir un objeto de conjunto de datos a partir de nuestros datos y, luego, dividir nuestros datos en lotes de `batch_size` para que se repitan para el número especificado de repeticiones (num_epochs). \n",
    "\n",
    "**NOTA:** Cuando el valor predeterminado de `num_epochs=None` se pasa como argumento a la función `repeat()`, los datos de entrada se repiten indefinidamente.\n",
    "\n",
    "A continuación, si `shuffle` está establecido en `True`, se aleatorizarán los datos de manera tal que se pasen al modelo al azar durante el entrenamiento. El argumento `buffer_size` de la función `shuffle` especifica el tamaño del conjunto de datos del que se tomará una muestra al azar.\n",
    "\n",
    "Finalmente, nuestra función de entrada construye una variable de iteración para el conjunto de datos y devuelve el siguiente lote de datos al regresor lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKZ9zNcHJtwc"
   },
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwa6UeA1V5F_"
   },
   "source": [
    " **NOTA:** Seguiremos usando esta misma función de entrada en ejercicios posteriores. Para obtener documentación más detallada de las funciones de entrada y la API del `Dataset`, consulta la [Guía para programadores de TensorFlow](https://www.tensorflow.org/programmers_guide/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YS50CQb2ooO"
   },
   "source": [
    " ### Paso 5: Entrena el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yP92XkzhU803"
   },
   "source": [
    " Ahora podemos llamar a `train()` en nuestro `linear_regressor` para entrenar el modelo. Uniremos `my_input_fn` en una `lambda` para poder pasar `my_feature` y `target` como argumentos (para obtener más detalles, consulta este [instructivo sobre funciones de entrada de TensorFlow](https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model)) y, para comenzar, entrenaremos el modelo para 100 pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5M-Kt6w8U803"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ef7d72bf998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m _ = linear_regressor.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmy_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_regressor' is not defined"
     ]
    }
   ],
   "source": [
    "_ = linear_regressor.train(\n",
    "    input_fn = lambda:my_input_fn(my_feature, targets),\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Nwxqxlx2sOv"
   },
   "source": [
    " ### Paso 6: Evalúa el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoDaF2dlJQG5"
   },
   "source": [
    " Realicemos predicciones sobre los datos de entrenamiento para ver qué tan bien los ajustó nuestro modelo durante el entrenamiento.\n",
    "**NOTA:** El error de entrenamiento mide qué tan bien ajusta los datos de entrenamiento tu modelo, pero **_no_** mide qué tan bien el modelo **_realiza generalizaciones con respecto a los datos nuevos_**. En ejercicios posteriores, explorarás cómo dividir los datos para evaluar la capacidad del modelo para realizar generalizaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDIxp6vcU809"
   },
   "outputs": [],
   "source": [
    "# Create an input function for predictions.\n",
    "# Note: Since we're making just one prediction for each example, we don't \n",
    "# need to repeat or shuffle the data here.\n",
    "prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Call predict() on the linear_regressor to make predictions.\n",
    "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# Print Mean Squared Error and Root Mean Squared Error.\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKWstXXPzOVz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ¿Este es un buen modelo? ¿Cómo determinarías la magnitud de este error?\n",
    "\n",
    "El error cuadrático medio (MSE) puede ser difícil de interpretar; es por esto que generalmente observamos el error de la raíz cuadrada de la media (RMSE) en su lugar. Una propiedad interesante del RMSE es que se puede interpretar en la misma escala que los objetivos originales.\n",
    "\n",
    "Comparemos el RMSE con la diferencia del mín. y el máx. de nuestros objetivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UwqGbbxP53O"
   },
   "outputs": [],
   "source": [
    "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
    "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
    "min_max_difference = max_house_value - min_house_value\n",
    "\n",
    "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
    "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
    "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
    "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JigJr0C7Pzit"
   },
   "source": [
    " Nuestro error abarca casi la mitad del rango de los valores objetivo. ¿Podemos obtener un mejor desempeño?\n",
    "\n",
    "Esta es la pregunta que molesta a todo programador de modelos. Desarrollemos algunas estrategias básicas para reducir el error del modelo.\n",
    "\n",
    "Lo primero que podemos hacer es observar qué tan bien coinciden nuestras predicciones con nuestros objetivos, en términos de estadísticas generales de resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "941nclxbzqGH",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = pd.DataFrame()\n",
    "calibration_data[\"predictions\"] = pd.Series(predictions)\n",
    "calibration_data[\"targets\"] = pd.Series(targets)\n",
    "calibration_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2-bf8Hq36y8",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " Bien, es posible que esta información resulte útil. ¿Cómo se compara el valor medio con el RMSE del modelo? ¿Qué ocurre con los diferentes cuantiles?\n",
    "\n",
    "También podemos visualizar los datos y la línea que aprendimos. Recuerda que la regresión lineal en un solo atributo puede representarse como una línea que asigna la entrada *x* al resultado *y*.\n",
    "\n",
    "Primero, obtendremos una muestra aleatoria uniforme de los datos para poder realizar una representación de dispersión que se pueda leer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGRIi3mAU81H"
   },
   "outputs": [],
   "source": [
    "sample = california_housing_dataframe.sample(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-JwuJBKU81J"
   },
   "source": [
    " A continuación, representaremos la línea que aprendimos, dibujándola a partir del término de ordenada al origen y la ponderación del atributo del modelo, junto con la representación de dispersión. La línea se mostrará de color rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "7G12E76-339G",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Get the min and max total_rooms values.\n",
    "x_0 = sample[\"total_rooms\"].min()\n",
    "x_1 = sample[\"total_rooms\"].max()\n",
    "\n",
    "# Retrieve the final weight and bias generated during training.\n",
    "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
    "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "# Get the predicted median_house_values for the min and max total_rooms values.\n",
    "y_0 = weight * x_0 + bias \n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
    "\n",
    "# Label the graph axes.\n",
    "plt.ylabel(\"median_house_value\")\n",
    "plt.xlabel(\"total_rooms\")\n",
    "\n",
    "# Plot a scatter plot from our data sample.\n",
    "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
    "\n",
    "# Display graph.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0lRt4USU81L"
   },
   "source": [
    " Esta línea inicial se ve muy alejada. Fíjate si puedes observar las estadísticas de resumen y ver la misma información codificada allí.\n",
    "\n",
    "En conjunto, estos controles de estado sugieren que posiblemente podamos encontrar una línea mucho más satisfactoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZWF67uv0HTG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Ajuste de los hiperparámetros del modelo\n",
    "Para este ejercicio, colocamos todo el código anterior en una sola función por cuestiones prácticas. Puedes llamar a la función con diferentes parámetros para ver el efecto.\n",
    "\n",
    "En esta función, procederemos en 10 períodos divididos uniformemente para poder observar la mejora del modelo en cada período.\n",
    "\n",
    "Para cada período, computaremos y graficaremos la pérdida de entrenamiento. Esto puede ayudarte a determinar cuándo converge un modelo o si este necesita más iteraciones.\n",
    "\n",
    "También representaremos los valores de ponderación de atributos y término de ordenada al origen aprendidos por el modelo en el tiempo. Esta es otra forma de ver cómo convergen los elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgSMeD5UU81N"
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate, steps, batch_size, input_feature=\"total_rooms\"):\n",
    "  \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: A `float`, the learning rate.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    input_feature: A `string` specifying a column from `california_housing_dataframe`\n",
    "      to use as input feature.\n",
    "  \"\"\"\n",
    "  \n",
    "  periods = 10\n",
    "  steps_per_period = steps / periods\n",
    "\n",
    "  my_feature = input_feature\n",
    "  my_feature_data = california_housing_dataframe[[my_feature]]\n",
    "  my_label = \"median_house_value\"\n",
    "  targets = california_housing_dataframe[my_label]\n",
    "\n",
    "  # Create feature columns.\n",
    "  feature_columns = [tf.feature_column.numeric_column(my_feature)]\n",
    "  \n",
    "  # Create input functions.\n",
    "  training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)\n",
    "  prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
    "  \n",
    "  # Create a linear regressor object.\n",
    "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  linear_regressor = tf.estimator.LinearRegressor(\n",
    "      feature_columns=feature_columns,\n",
    "      optimizer=my_optimizer\n",
    "  )\n",
    "\n",
    "  # Set up to plot the state of our model's line each period.\n",
    "  plt.figure(figsize=(15, 6))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.title(\"Learned Line by Period\")\n",
    "  plt.ylabel(my_label)\n",
    "  plt.xlabel(my_feature)\n",
    "  sample = california_housing_dataframe.sample(n=300)\n",
    "  plt.scatter(sample[my_feature], sample[my_label])\n",
    "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print(\"Training model...\")\n",
    "  print(\"RMSE (on training data):\")\n",
    "  root_mean_squared_errors = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    linear_regressor.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "    # Take a break and compute predictions.\n",
    "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "    \n",
    "    # Compute loss.\n",
    "    root_mean_squared_error = math.sqrt(\n",
    "        metrics.mean_squared_error(predictions, targets))\n",
    "    # Occasionally print the current loss.\n",
    "    print(\"  period %02d : %0.2f\" % (period, root_mean_squared_error))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    root_mean_squared_errors.append(root_mean_squared_error)\n",
    "    # Finally, track the weights and biases over time.\n",
    "    # Apply some math to ensure that the data and line are plotted neatly.\n",
    "    y_extents = np.array([0, sample[my_label].max()])\n",
    "    \n",
    "    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n",
    "    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "    x_extents = (y_extents - bias) / weight\n",
    "    x_extents = np.maximum(np.minimum(x_extents,\n",
    "                                      sample[my_feature].max()),\n",
    "                           sample[my_feature].min())\n",
    "    y_extents = weight * x_extents + bias\n",
    "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
    "  print(\"Model training finished.\")\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.ylabel('RMSE')\n",
    "  plt.xlabel('Periods')\n",
    "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "  plt.tight_layout()\n",
    "  plt.plot(root_mean_squared_errors)\n",
    "\n",
    "  # Output a table with calibration data.\n",
    "  calibration_data = pd.DataFrame()\n",
    "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
    "  calibration_data[\"targets\"] = pd.Series(targets)\n",
    "  display.display(calibration_data.describe())\n",
    "\n",
    "  print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kg8A4ArBU81Q"
   },
   "source": [
    " ## Tarea 1: Logra un RMSE de 180 o más bajo\n",
    "\n",
    "Ajusta los hiperparámetros del modelo para mejorar la pérdida y adaptar mejor la distribución objetivo.\n",
    "Si después de aproximadamente 5 minutos tienes problemas para obtener un RMSE de 180 o más bajo, comprueba la solución para conocer una combinación posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "UzoZUSdLIolF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    learning_rate=0.00001,\n",
    "    steps=100,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajVM7rkoYXeL"
   },
   "source": [
    " ### Solución\n",
    "\n",
    "Haz clic más abajo para conocer una solución posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3zmldDwYy5c"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    learning_rate=0.00002,\n",
    "    steps=500,\n",
    "    batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8H0_D4vYa49"
   },
   "source": [
    " Esta es solo una configuración posible; es posible que existan otras combinaciones de configuraciones que también den buenos resultados. Ten en cuenta que, en general, este ejercicio no se trata de buscar la *mejor* configuración, sino de ayudarte a desarrollar tu intuición sobre cómo el ajuste de la configuración del modelo afecta la calidad de la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QU5sLyYTqzqL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### ¿Hay una heurística estándar para el ajuste del modelo?\n",
    "\n",
    "Esta es una pregunta frecuente. La respuesta breve es que los efectos de los diferentes hiperparámetros dependen de los datos. Por lo tanto, no hay reglas estrictas; debes probarlos en tus datos.\n",
    "\n",
    "Dicho esto, aquí se incluyen algunas reglas generales que pueden ayudarte como guía:\n",
    "\n",
    " * El error de entrenamiento debe disminuir constantemente, de manera abrupta al principio y eventualmente estancarse a medida que converge el entrenamiento.\n",
    " * Si el entrenamiento no convirgió, prueba ejecutarlo durante más tiempo.\n",
    " * Si el error de entrenamiento disminuye muy lentamente, aumentar la tasa de entrenamiento puede ayudar a que disminuya más rápido.\n",
    "   * Sin embargo, en algunas ocasiones puede ocurrir exactamente lo opuesto si la tasa de aprendizaje es demasiado alta.\n",
    " * Si el error de entrenamiento varía extremadamente, prueba disminuir la tasa de aprendizaje.\n",
    "   * Una tasa de aprendizaje más baja con un número más alto de pasos o un tamaño del lote más grande suelen ser una buena combinación.\n",
    " * Los tamaños del lote muy pequeños también pueden causar inestabilidad. Primero prueba valores más altos, como 100 o 1,000, y disminúyelos hasta que observes degradación.\n",
    "\n",
    "Como dijimos antes, nunca te rijas estrictamente por estas reglas generales, porque los efectos dependen de los datos. Siempre debes experimentar y verificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpV-uF_cBCBU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ## Tarea 2: Prueba un atributo diferente\n",
    "\n",
    "Observa si puedes obtener un mejor desempeño al reemplazar el atributo `total_rooms` por el atributo `population`.\n",
    "\n",
    "No dediques más de 5 minutos a esta actividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMyOxzb0ZlAH"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ci1ISxxrZ7v0"
   },
   "source": [
    " ### Solución\n",
    "\n",
    "Haz clic más abajo para conocer una solución posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjdQQCduZ7BV"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    learning_rate=0.00002,\n",
    "    steps=1000,\n",
    "    batch_size=5,\n",
    "    input_feature=\"population\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ajVM7rkoYXeL",
    "ci1ISxxrZ7v0",
    "copyright-notice"
   ],
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
