{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este módulo se centra en la generalización. Para desarrollar algo de intuición sobre este concepto, observarás tres figuras. Imagina que cada punto en estas figuras representa la posición de un árbol en un bosque. Los dos colores tienen los siguientes significados:\n",
    "\n",
    "* Los puntos azules representan árboles enfermos.\n",
    "* Los puntos anaranjados representan árboles sanos.\n",
    "\n",
    "Con eso en mente, echa un vistazo a la Figura 1.\n",
    "\n",
    "![graph](img/GeneralizationA.png \"graph\")\n",
    "\n",
    "**Figura 1. Árboles enfermos (azules) y sanos (anaranjados).**\n",
    "\n",
    "¿Puedes imaginar un buen modelo para predecir los árboles enfermos o sanos subsiguientes? Tómate un momento para dibujar mentalmente un arco que divida los puntos azules de los anaranjados, o enlaza mentalmente un lote de puntos azules o anaranjados. Luego, observa la Figura 2, que muestra cómo un determinado modelo de aprendizaje automático separó los árboles enfermos de los sanos. Ten en cuenta que este modelo produjo una pérdida muy baja.\n",
    "\n",
    "![graph0](img/GeneralizationB.png \"graph0\")\n",
    "\n",
    "**Figura 2. Un modelo complejo para distinguir los árboles enfermos de los sanos.**\n",
    "\n",
    "A primera vista, el modelo que se muestra en la Figura 2 parecía hacer un trabajo excelente al separar los árboles enfermos de los sanos. ¿No es así?\n",
    "\n",
    "\n",
    "### ¿Sigue siendo un modelo malo a pesar de la pérdida baja?\n",
    "\n",
    "La Figura 3 muestra qué ocurrió cuando se agregaron datos al modelo. Resultó que el modelo se adaptó de manera muy deficiente a los datos nuevos. Observa que el modelo categorizó mal muchos de los datos nuevos.\n",
    "\n",
    "![graph1](img/GeneralizationC.png \"graph1\")\n",
    "\n",
    "**Figura 3. El modelo no se desempeñó bien al predecir datos nuevos.**\n",
    "\n",
    "\n",
    "Generalización: Riesgos del sobreajuste\n",
    "Tiempo estimado: 10 minutos\n",
    "Este módulo se centra en la generalización. Para desarrollar algo de intuición sobre este concepto, observarás tres figuras. Imagina que cada punto en estas figuras representa la posición de un árbol en un bosque. Los dos colores tienen los siguientes significados:\n",
    "\n",
    "Los puntos azules representan árboles enfermos.\n",
    "Los puntos anaranjados representan árboles sanos.\n",
    "Con eso en mente, echa un vistazo a la Figura 1.\n",
    "\n",
    "Esta figura contiene alrededor de 50 puntos, de los cuales la mitad son azules y la otra mitad son anaranjados. Los puntos anaranjados están principalmente en el cuadrante suroeste, aunque algunos puntos anaranjados se pasan un poco a los otros tres cuadrantes. Los puntos azules están principalmente en el cuadrante noreste, aunque algunos puntos azules se salen a los otros cuadrantes.\n",
    "\n",
    "Figura 1. Árboles enfermos (azules) y sanos (anaranjados).\n",
    "\n",
    "¿Puedes imaginar un buen modelo para predecir los árboles enfermos o sanos subsiguientes? Tómate un momento para dibujar mentalmente un arco que divida los puntos azules de los anaranjados, o enlaza mentalmente un lote de puntos azules o anaranjados. Luego, observa la Figura 2, que muestra cómo un determinado modelo de aprendizaje automático separó los árboles enfermos de los sanos. Ten en cuenta que este modelo produjo una pérdida muy baja.\n",
    "\n",
    "Haz clic para ver la Figura 2.\n",
    "Esta figura contiene la misma disposición de puntos azules y anaranjados que la Figura 1.Sin embargo, esta figura incluye con exactitud casi todos los puntos azules y anaranjados con una colección de formas complejas.\n",
    "\n",
    "Figura 2. Un modelo complejo para distinguir los árboles enfermos de los sanos.\n",
    "\n",
    "A primera vista, el modelo que se muestra en la Figura 2 parecía hacer un trabajo excelente al separar los árboles enfermos de los sanos. ¿No es así?\n",
    "\n",
    " \n",
    "\n",
    "¿Sigue siendo un modelo malo a pesar de la pérdida baja?\n",
    "La Figura 3 muestra qué ocurrió cuando se agregaron datos al modelo. Resultó que el modelo se adaptó de manera muy deficiente a los datos nuevos. Observa que el modelo categorizó mal muchos de los datos nuevos.\n",
    "\n",
    "Se trata de la misma ilustración que la Figura 2, excepto por alrededor de 100 puntos más que se agregaron. Muchos de los puntos nuevos quedan fuera del modelo predicho.\n",
    "\n",
    "Figura 3. El modelo no se desempeñó bien al predecir datos nuevos.\n",
    "\n",
    "El modelo que se muestra en las Figuras 2 y 3 **sobreajusta** las peculiaridades de los datos con los que se entrenó. Un modelo sobreajustado obtiene una pérdida baja durante el entrenamiento, pero no se desempeña bien al predecir datos nuevos. Si un modelo se adapta bien a la muestra actual, ¿cómo podemos confiar en que realizará buenas predicciones sobre los datos nuevos? Como verás más adelante, el sobreajuste se genera al desarrollar un modelo más complejo que lo necesario. La presión fundamental del aprendizaje automático está en el ajuste correcto de nuestros datos, pero también en el ajuste de los datos de la manera más simple posible.\n",
    "\n",
    "El objetivo del aprendizaje automático es realizar buenas predicciones sobre datos nuevos obtenidos de una distribución probablemente verdadera (oculta). Lamentablemente, el modelo no puede ver toda la verdad; este solo puede tomar una muestra de un conjunto de datos de entrenamiento. Si un modelo se adapta bien a los ejemplos actuales, ¿cómo podemos confiar en que también realizará buenas predicciones sobre los ejemplos nunca antes vistos?\n",
    "\n",
    "Guillermo de Ockham, un fraile y filósofo del siglo XIV, amaba la simplicidad. Creía que los científicos debían preferir las fórmulas o teorías más simples en lugar de aquellas más complejas. Para expresar la navaja de Ockham en términos de aprendizaje automático:\n",
    "Cuanto menos complejo sea un modelo de AA, más probable será que un buen resultado empírico no se deba simplemente a las peculiaridades de la muestra.\n",
    "\n",
    "En la actualidad, hemos formalizado la navaja de Ockham en los campos de la **teoría del aprendizaje estadístico** y **la teoría del aprendizaje computacional**. Estos campos han desarrollado **límites de generalización**, es decir, una descripción estadística de la capacidad de un modelo para generalizar sobre datos nuevos en función de factores como los siguientes:\n",
    "\n",
    "* la complejidad del modelo\n",
    "* el rendimiento del modelo con respecto a los datos de entrenamiento\n",
    "\n",
    "Si bien el análisis teórico ofrece garantías formales en supuestos idealizados, esos límites pueden ser difíciles de aplicar en la práctica. El Curso intensivo de aprendizaje automático se centra más bien en la evaluación empírica, a fin de juzgar la capacidad de un modelo para generalizar sobre datos nuevos.\n",
    "\n",
    "Un modelo de aprendizaje automático tiene como objetivo realizar buenas predicciones sobre datos nuevos nunca antes vistos. Pero, si desarrollas un modelo a partir de tu conjunto de datos, ¿cómo obtendrías los datos nunca antes vistos? Una forma es dividir el conjunto de datos en dos subconjuntos:\n",
    "\n",
    "* **Conjunto de entrenamiento**: Un subconjunto para entrenar un modelo.\n",
    "* **Conjunto de prueba**: Un subconjunto para probar el modelo.\n",
    "\n",
    "Un buen rendimiento en el conjunto de prueba es un indicador útil de buen rendimiento en los datos nuevos en general, suponiendo lo siguiente:\n",
    "\n",
    "* El conjunto de prueba es lo suficientemente grande.\n",
    "* No haces trampa usando el mismo conjunto de prueba una y otra vez.\n",
    "\n",
    "\n",
    "### Las condiciones del AA\n",
    "\n",
    "Las tres suposiciones básicas siguientes guían la generalización:\n",
    "\n",
    "* Los ejemplos se obtienen **independiente e idénticamente** (**i.i.d**) de manera aleatoria de la distribución. En otras palabras, los ejemplos no se influyen entre sí. (Una explicación alternativa: i.i.d. es una forma de hacer referencia a la aleatoriedad de las variables).\n",
    "* La distribución es estacionaria, es decir, no cambia dentro del conjunto de datos.\n",
    "* Los ejemplos se obtienen de particiones de la misma distribución.\n",
    "\n",
    "En la práctica, a veces infringimos estas suposiciones. Por ejemplo:\n",
    "\n",
    "* Considera un modelo que elige los anuncios para mostrar. La suposición de i.i.d. se infringiría si, en parte, el modelo basara su elección en función de los anuncios que el usuario visualizó anteriormente.\n",
    "* Considera un conjunto de datos que contenga la información de ventas minoristas de un año. Las compras de los usuarios cambian todas las temporadas, lo cual infringiría la estacionariedad.\n",
    "\n",
    "Cuando sabemos que se infringe alguna de las tres suposiciones básicas anteriores, debemos prestar mucha atención a las métricas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
