{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el módulo anterior, se presentó la idea de dividir el conjunto de datos en dos subconjuntos:\n",
    "\n",
    "* **Conjunto de entrenamiento**: Un subconjunto para entrenar un modelo.\n",
    "* **Conjunto de prueba**: Un subconjunto para probar el modelo entrenado.\n",
    "\n",
    "Imagina dividir el único conjunto de datos de la siguiente manera:\n",
    "\n",
    "![graph](img/PartitionTwoSets.svg \"graph\")\n",
    "\n",
    "**Figura 1. División de un único conjunto de datos en un conjunto de entrenamiento y uno de prueba.**\n",
    "\n",
    "Asegúrate de que tu conjunto de prueba reúna las siguientes dos condiciones:\n",
    "\n",
    "* Que sea lo suficientemente grande como para generar resultados significativos desde el punto de vista estadístico.\n",
    "* Que sea representativo de todo el conjunto de datos. En otras palabras, no elijas un conjunto de prueba con características diferentes al del conjunto de entrenamiento.\n",
    "\n",
    "Si suponemos que el conjunto de prueba reúne estas dos condiciones, tu objetivo es crear un modelo que generalice los datos nuevos de forma correcta. Nuestro conjunto de prueba sirve como proxy para los datos nuevos. Por ejemplo, considera la siguiente figura. Observa que el modelo aprendido para los datos de entrenamiento es muy simple. Este modelo no hace un trabajo perfecto. Algunas predicciones son incorrectas. Sin embargo, este modelo funciona de la misma manera tanto en los datos de prueba como en los de entrenamiento. En otras palabras, este modelo simple no sobreajusta los datos de entrenamiento.\n",
    "\n",
    "![graph1](img/TrainingDataVsTestData.svg \"graph1\")\n",
    "\n",
    "**Figura 2. Validación del modelo entrenado con los datos de prueba.**\n",
    "\n",
    "**Nunca uses los datos de prueba para el entrenamiento**. Si ves resultados sorpresivamente positivos en tus métricas de evaluación, es posible que estés usando los datos de prueba para el entrenamiento. Por ejemplo, tener una precisión alta puede ser un indicativo de que se filtraron datos de prueba en los de entrenamiento.\n",
    "\n",
    "Por ejemplo, imagina un modelo que prediga si un correo electrónico es spam, tomando como atributos el asunto, el cuerpo y la dirección de correo electrónico del remitente. Distribuimos los datos en conjuntos de entrenamiento y prueba en una proporción de 80 a 20. Después del entrenamiento, el modelo alcanza el 99% de precisión en ambos conjuntos. Esperamos una precisión menor en el conjunto de prueba, por lo que volvemos a analizar los datos y descubrimos que muchos de los ejemplos en este conjunto están duplicados en el conjunto de entrenamiento (arrastramos entradas duplicadas para el mismo spam de una base de datos de entrada antes de separar los datos). Involuntariamente, usamos algunos de los datos de prueba para el entrenamiento y, como resultado, no logramos medir de forma precisa de qué manera el modelo generaliza los datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
