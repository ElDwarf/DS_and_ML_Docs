{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida para la regresión logística\n",
    "\n",
    "La función de pérdida para la regresión lineal es una pérdida cuadrática. La función de pérdida para la regresión logística es la **Pérdida logística**, que se define de la siguiente manera:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "PerdidaLogistica = \\sum_{(x,y) \\epsilon D}{-ylog(y')-(1-y)log(1-y')}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $(x,y) \\epsilon D$ es el conjunto de datos que contiene muchos ejemplos etiquetados, en pares (x,y).\n",
    "* $y$ es la etiqueta en un ejemplo etiquetado. Dado que se trata de regresión logística, cada valor de y debe ser 0 o 1.\n",
    "* $y'$ es el valor predicho (un valor entre 0 y 1), dado el conjunto de atributos en x.\n",
    "\n",
    "La ecuación para la Pérdida logística está íntimamente relacionada con la dimensión de la entropía de Shannon en el ámbito de la teoría de la información. También es el logaritmo negativo de la función de probabilidad, si adoptamos la distribución de Bernoulli de y. De hecho, si minimizamos la función de pérdida, obtenemos un rendimiento estimado máximo de probabilidad.\n",
    "\n",
    "#### Regularización en la regresión logística\n",
    "\n",
    "La regularización es sumamente importante en el modelo de regresión logística. Sin regularización, la naturaleza asintótica de la regresión logística seguiría teniendo una tendencia de pérdida de 0 en grandes dimensiones. En consecuencia, la mayoría de los modelos de regresión logística usan una de las dos estrategias que se describen a continuación para disminuir la complejidad del modelo:\n",
    "\n",
    "* Regularización $L_2$.\n",
    "* Interrupción anticipada, es decir, limitar el número de pasos de entrenamiento o la tasa de aprendizaje.\n",
    "\n",
    "(Hablaremos sobre una tercera estrategia —regularización de $L_1$— en un próximo módulo).\n",
    "\n",
    "Imagina que asignas un ID único a cada ejemplo y los unes a su propio atributo. Si no especificas una función de regularización, el modelo se sobreajustará por completo. El motivo es que el modelo intentará llevar las pérdidas a cero en todos los ejemplos sin conseguirlo, lo que hará que los pesos del atributo de cada indicador lleguen a +infinito o -infinito. Esto puede suceder en datos de grandes dimensiones con combinaciones de atributos, cuando hay una gran cantidad de combinaciones poco comunes que suceden solo en un ejemplo dado.\n",
    "\n",
    "Afortunadamente, este problema se evita con el uso de $L_2$ o interrupción anticipada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
