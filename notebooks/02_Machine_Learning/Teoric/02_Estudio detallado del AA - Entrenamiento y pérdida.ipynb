{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar** un modelo simplemente significa aprender (determinar) valores correctos para todas las ponderaciones y las ordenadas al origen de los ejemplos etiquetados. En un aprendizaje supervisado, el algoritmo de un aprendizaje automático construye un modelo al examinar varios ejemplos e intentar encontrar un modelo que minimice la pérdida. Este proceso se denomina **minimización del riesgo empírico**.\n",
    "\n",
    "La pérdida es una penalidad por una predicción incorrecta. Esto quiere decir que la **pérdida** es un número que indica qué tan incorrecta fue la predicción del modelo en un solo ejemplo. Si la predicción del modelo es perfecta, la pérdida es cero; de lo contrario, la pérdida es mayor. El objetivo de entrenar un modelo es encontrar un conjunto de ponderaciones y ordenadas al origen que, en promedio, tengan pérdidas bajas en todos los ejemplos. Por ejemplo, la Figura 3 muestra un modelo al lado izquierdo con una pérdida alta, y al lado derecho un modelo con pérdida baja. Ten en cuenta lo siguiente con respecto a la imagen:\n",
    "\n",
    "* La flecha roja representa la pérdida.\n",
    "* La línea azul representa las predicciones.\n",
    "\n",
    "![graph](img/LossSideBySide.png \"graph\")\n",
    "\n",
    "**Figura 3. Pérdida alta en el modelo de la izquierda; pérdida baja en el modelo de la derecha.**\n",
    "\n",
    "\n",
    "Ten en cuenta que las flechas rojas en la figura izquierda son mucho más largas que las de la figura derecha. Claramente, la línea azul en la figura de la derecha es un modelo de predicción mucho más acertado que la línea azul en la figura de la izquierda.\n",
    "\n",
    "Tal vez te preguntes si puedes crear una función matemática (una función de pérdida) que sume las pérdidas individuales de una forma que tenga sentido.\n",
    "\n",
    "Pérdida al cuadrado: Una función popular de pérdida\n",
    "\n",
    "Los modelos de regresión lineal que se examinan aquí usan una función de pérdida llamada **pérdida al cuadrado** (también conocida como pérdida **${L}_2$**). A continuación, se muestra la pérdida al cuadrado para un único ejemplo:\n",
    "\n",
    "```\n",
    "  = the square of the difference between the label and the prediction\n",
    "  = (observation - prediction(x))2\n",
    "  = (y - y')2\n",
    "```\n",
    "\n",
    "El **error cuadrático medio** (**ECM**) es el promedio de la pérdida al cuadrado de cada ejemplo. Para calcular el ECM, sumamos todas las pérdidas al cuadrado de los ejemplos individuales y, luego, lo dividimos por la cantidad de ejemplos:\n",
    "\n",
    "\\begin{equation*}\n",
    "ECM = \\frac{1}{N} \\sum_{(x,y) \\in D} (y - preduccion(x))^2\n",
    "\\end{equation*}\n",
    "\n",
    "donde:\n",
    "\n",
    "* $(x, y)$ es un ejemplo en el que\n",
    "  * $x$ es el conjunto de atributos (p. ej., temperatura, edad y éxito para aparearse) que el modelo usa para realizar las predicciones.\n",
    "  * $y$ es la etiqueta del ejemplo (p. ej., cantos por minuto).\n",
    "* $prediccion(x)$ es un atributo de las ponderaciones y las ordenadas al origen en combinación con el conjunto de atributos $x$.\n",
    "* $D$ es el conjunto de datos que contiene muchos ejemplos etiquetados, que son los pares $(x, y)$.\n",
    "* $n$ es la cantidad de ejemplos en $D$.\n",
    "\n",
    "Si bien ECM se usa comúnmente en el aprendizaje automático, no es la única función de pérdida práctica ni la mejor para todas las circunstancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
